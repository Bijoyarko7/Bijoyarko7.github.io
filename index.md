---
layout: homepage
---

## Biography

Hi! I’m a third-year PhD student in the Computer Science department at Virginia Tech, advised by Prof. [Chandan Reddy](https://people.cs.vt.edu/reddy/). Prior to starting my PhD, I worked at [Gilead Sciences](https://www.gilead.com/) as AI Scientist Intern. I completed my MS in Operations Research at Virginia Tech, and obtained my BS from [Sharif University of Technology](https://en.sharif.edu/).

## Research Interests
<!-- My primary research interests revolve around AI for Science and Engineering. Most of my works fall into one of these categories: -->
My primary research interests revolve around AI for symbolic generation (code, math & reasoning) and its potentials for scientific discovery. Most of my works fall into one of these categories:
<!-- Most of my works focus on extending Reinforcement Learning and Transformer models to non-text domains, falling into one of these categories: -->
- **AI for Math**, with a focus on uncovering hidden mathematical laws within data (equation discovery, symbolic regression)
- **AI for Code**, with a focus on automating program synthesis, contextual code generation, and neuro-symbolic programming
<!-- - **Deep Learning for Time Series**, with a focus on sensor data fusion and forecasting -->

<!-- - **Deep Learning for Time Series Forecasting**, with a focus on exploring GNN and ODE forecasting methods -->

If you're interested in my research, would like to discuss relevant topics, or explore potential collaborations, please feel free to get in touch :) 

I am best reached by email at [parshinshojaee@vt.edu](mailto:parshinshojaee@vt.edu)



## News
- **[May. 2024]** I’m thrilled to start my internship at [Adobe](https://www.adobe.com/home) in this summer!
- **[Apr. 2024]** <strong style="color: red;">New Preprint!</strong> Our [LLM-SR](https://arxiv.org/abs/2404.18400) paper on using LLMs for scientific equation discovery is released.
- **[Jan. 2024]** Our [SNIP (Symbolic-Numeric Pretraining)](https://openreview.net/forum?id=KZSEgJGPxu) paper is accepted to [**ICLR 2024**](https://iclr.cc/Conferences/2024) as <strong style="color: red;">Spotlight</strong>!
- **[Dec. 2023]** I will be at NeurIPS 2023 in New Orleans, presenting our [TPSR](https://proceedings.neurips.cc/paper_files/paper/2023/hash/8ffb4e3118280a66b192b6f06e0e2596-Abstract-Conference.html) paper. Please reach out if you want to chat! 
- **[Sep. 2023]** Our [TPSR](https://proceedings.neurips.cc/paper_files/paper/2023/hash/8ffb4e3118280a66b192b6f06e0e2596-Abstract-Conference.html) paper on equation disocvery with transformers and planning is accepted to [**NeurIPS 2023**](https://nips.cc/)!
- **[Jul. 2023]** Our [PPOCoder](https://openreview.net/forum?id=0XBuaxqEcG) paper on code generation with deep RL is accepted to [**TMLR**](https://jmlr.org/tmlr/)! 
- **[Dec. 2022]** Our [GRAM-ODE](https://openreview.net/forum?id=Oq5XKRVYpQ) paper on forecasting with graph ODEs is accepted to [**TMLR**](https://jmlr.org/tmlr/)! 
<!-- - **[May. 2022]** I’m thrilled to start my internship at [Gilead Sciences](https://www.gilead.com/) in this upcoming summer 2022! -->
<!-- - **[Jan. 2021]**  I started my PhD at [Virginia Tech](https://cs.vt.edu/). -->
<!-- - **[Apr. 2019]** One paper was accepted to TMLR 2023. -->


<!-- https://tmlr.infinite-conf.org/paper_pages/0XBuaxqEcG.html -->


{% include_relative _includes/publications.md %}

{% include_relative _includes/services.md %}



